{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_file(filename):\n",
    "    print(f'Exporting {filename}')\n",
    "    with open(f'SERIAL_CAPTURE/{filename}.json') as f:\n",
    "        d = json.load(f)\n",
    "\n",
    "\n",
    "    def strip_data(packet, len):\n",
    "        hex = packet.split(\":\")\n",
    "        hex = hex[-len:]\n",
    "        return ''.join(hex)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for packet in d:\n",
    "\n",
    "        data_len = int(packet['_source']['layers']['usb']['usb.data_len'])\n",
    "\n",
    "        packet_str = packet['_source']['layers']['ftdi-ft']\n",
    "\n",
    "        time = packet['_source']['layers']['frame']['frame.time_relative']\n",
    "\n",
    "        elem = {}\n",
    "\n",
    "        if \"ftdi-ft.if_a_tx_payload\" in packet_str:\n",
    "            #tx\n",
    "            elem = {\n",
    "            \"time\": time,\n",
    "            \"dir\": \"tx\",\n",
    "            \"packet\": strip_data(packet_str[\"ftdi-ft.if_a_tx_payload\"], data_len),\n",
    "            \"len\": data_len,\n",
    "            }\n",
    "        else:\n",
    "            #rx\n",
    "            elem = {\n",
    "            \"time\": time,\n",
    "            \"dir\": \"rx\",\n",
    "            \"packet\": strip_data(packet_str[\"ftdi-ft.if_a_rx_payload\"], data_len),\n",
    "            \"len\": data_len,\n",
    "            }\n",
    "\n",
    "        data.append(elem)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Create an empy dataframe with the same columns as df\n",
    "    df_concat = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    #itterate over df \n",
    "\n",
    "    # COMINE PACKETS\n",
    "    packet = \"\"\n",
    "    length = len(df)\n",
    "    for index, row in df.iterrows():\n",
    "        direction = row['dir']\n",
    "        packet = packet + row['packet']\n",
    "\n",
    "\n",
    "        if index == length - 1:\n",
    "            # Over 2 as two chars per byte\n",
    "            df_row = pd.DataFrame([[row['time'], row['dir'], packet, int(len(packet)/2)]], columns=df.columns)\n",
    "            df_concat = pd.concat([df_concat, df_row])\n",
    "            packet = \"\"\n",
    "            break\n",
    "            \n",
    "\n",
    "        if df.iloc[index+1]['dir'] != direction:\n",
    "            df_row = pd.DataFrame([[row['time'], row['dir'], packet, int(len(packet)/2)]], columns=df.columns)\n",
    "            df_concat = pd.concat([df_concat, df_row])\n",
    "            packet = \"\"\n",
    "        \n",
    "\n",
    "    df_concat.to_csv(f'SERIAL_CAPTURE/{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting errors_200\n",
      "Exporting capp_press_prog_nobean\n",
      "Exporting button_press_mocha\n",
      "Exporting clear_errors\n",
      "Exporting button_press_other\n",
      "Exporting americano_prog_noerror\n",
      "Exporting button_press_white_coffee\n",
      "Exporting button_press_cappuccino_program_nobeans\n",
      "Exporting read_errors\n",
      "Exporting mach_conf\n",
      "Exporting button_press_cappuccino_program_noerr_1\n",
      "Exporting americano_noerror\n",
      "Exporting button_press_cappuccino\n",
      "Exporting americano_161_error\n",
      "Exporting first_runup\n",
      "Exporting button_press_hot_chocolate\n",
      "Exporting button_press_americano_good_run_then_no_beans\n",
      "Exporting americano_press_prog_goodrun_then_nobeans\n",
      "Exporting capp_press_prog_goodrun\n",
      "Exporting americano_press\n",
      "Exporting button_press_latte_works\n",
      "Exporting errors_200_run2\n",
      "Exporting button_press_americano\n",
      "Exporting bev_config\n",
      "Exporting button_press_hot_water\n",
      "Exporting button_press_latte\n"
     ]
    }
   ],
   "source": [
    "#get list of file in directory with extension json and remove extension\n",
    "\n",
    "# WIRESHARK FILTER -> ftdi-ft&&(ftdi-ft.if_a_rx_payload||ftdi-ft.if_a_tx_payload)\n",
    "import os\n",
    "files = [f.split('.')[0] for f in os.listdir('SERIAL_CAPTURE') if f.endswith('.json')]\n",
    "\n",
    "for file in files:\n",
    "    export_file(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
