{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0300010000000100814500 - 0003000000130009000000ea\n",
    "customer_data = \"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\"\n",
    "# 0300010000000100814500 - 0003000000130008000000e9\n",
    "service_data = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signed      1.953064e+09\n",
      "unsigned    1.953065e+09\n",
      "float       7.396981e+31\n",
      "index       2.080000e+02\n",
      "Name: 57686974, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "# byte to value conversions\n",
    "\n",
    "def convert_b_signed(byte):\n",
    "    return struct.unpack('b', bytes.fromhex(byte))[0]\n",
    "\n",
    "def convert_b_unsigned(byte):\n",
    "    return struct.unpack('B', bytes.fromhex(byte))[0]\n",
    "\n",
    "def convert_b_char(byte):\n",
    "    return struct.unpack('c', bytes.fromhex(byte))[0]\n",
    "\n",
    "# LITTLE ENDIAN\n",
    "def convert_unsigned(hex):\n",
    "    dec = int.from_bytes(bytes.fromhex(hex), byteorder=\"little\")\n",
    "    return dec\n",
    "\n",
    "def convert_signed(hex):\n",
    "    bits = len(hex) * 4\n",
    "    dec  = convert_unsigned(hex)\n",
    "    if dec > (bits-1)**2:\n",
    "        dec = dec - bits**2\n",
    "    return dec\n",
    "\n",
    "def convert_2b_float(byte_2):\n",
    "    return struct.unpack('e', bytes.fromhex(byte_2))[0]\n",
    "\n",
    "def convert_4b_float(byte_4):\n",
    "    return struct.unpack('f', bytes.fromhex(byte_4))[0]\n",
    "\n",
    "def convert_8b_double(byte_8):\n",
    "    return struct.unpack('d', bytes.fromhex(byte_8))[0]\n",
    "\n",
    "def convert_string(byte):\n",
    "    return struct.unpack('s', bytes.fromhex(byte))[0]\n",
    "\n",
    "\n",
    "\n",
    "def convert_byte(byte):\n",
    "    char = convert_b_char(byte)\n",
    "    ub = convert_unsigned(byte)\n",
    "    sb = convert_signed(byte)\n",
    "\n",
    "    return [sb , ub, char]\n",
    "\n",
    "def convert_2b(byte_2):\n",
    "    u2 = convert_unsigned(byte_2)\n",
    "    s2 = convert_signed(byte_2)\n",
    "    float_s = convert_2b_float(byte_2)\n",
    "    return [s2, u2, float_s ]\n",
    "\n",
    "def convert_4b(byte_4):\n",
    "    u4 = convert_unsigned(byte_4)\n",
    "    s4 = convert_signed(byte_4)\n",
    "    f = convert_4b_float(byte_4)\n",
    "\n",
    "    return [ s4, u4, f]\n",
    "\n",
    "def convert_8b(byte_8):\n",
    "    u8 = convert_unsigned(byte_8)\n",
    "    s8 = convert_signed(byte_8)\n",
    "    double = convert_8b_double(byte_8)\n",
    "\n",
    "    return [s8, u8, double]\n",
    "\n",
    "# Windows hexstring into byte, b2, b4, b8 and converts data into typical data types\n",
    "# Returns dataframes with the converted data (index indicated position of data in hexstring)\n",
    "def convert_hexstring(data : str):\n",
    "    # Window string into chunks of different byte sizes\n",
    "    # Make window jump by 2 chars as 2chars = 1 byte\n",
    "    b =  [data[(i*2):(i*2)+2] for i in range(0, int(len(data)/2))]\n",
    "    b2 = [data[(i*2):(i*2)+4] for i in range(0, int(len(data)/2-1))]\n",
    "    b4 = [data[(i*2):(i*2)+8] for i in range(0, int(len(data)/2-3))]\n",
    "    b8 =  [data[(i*2):(i*2)+16] for i in range(0, int(len(data)/2-7))]\n",
    "\n",
    "\n",
    "    b_conversion  = pd.DataFrame(columns=['byte',  'signed', 'unsigned', 'char'])\n",
    "    b2_conversion = pd.DataFrame(columns=['2byte', 'signed', 'unsigned', 'float'])\n",
    "    b4_conversion = pd.DataFrame(columns=['4byte', 'signed', 'unsigned', 'float'])\n",
    "    b8_conversion = pd.DataFrame(columns=['8byte', 'signed', 'unsigned', 'double'])\n",
    " \n",
    "    \"\"\"\n",
    "    conv = []\n",
    "    for x in b_conversion['char'].values:\n",
    "        try:\n",
    "            a = str(x, 'utf-8')\n",
    "            conv.append(a)\n",
    "        except:\n",
    "            conv.append(\"@\")\n",
    "    \"\"\"\n",
    "    string = \"\"\n",
    "    \n",
    "    b_conversion = b_conversion.drop('char', axis=1)\n",
    "\n",
    "    for i, byte in enumerate(b):\n",
    "        b_conversion.loc[i] = [byte] + convert_byte(byte)[0:2]\n",
    "\n",
    "    for i, byte_2 in enumerate(b2):\n",
    "        b2_conversion.loc[i] = [byte_2] + convert_2b(byte_2)\n",
    "    \n",
    "    for i, byte_4 in enumerate(b4):\n",
    "        b4_conversion.loc[i] = [byte_4] + convert_4b(byte_4)\n",
    "    \n",
    "    for i, byte_8 in enumerate(b8):\n",
    "        b8_conversion.loc[i] = [byte_8] + convert_8b(byte_8)\n",
    "\n",
    "    return b_conversion, b2_conversion, b4_conversion, b8_conversion, string\n",
    "\n",
    "strings = [\n",
    "    \"4C617474\", # Latte           INDEX: 58\n",
    "    \"43617070\", # Cappuccino      INDEX: 133\n",
    "    \"57686974\"  # White coffee    INDEX: 208\n",
    "]\n",
    "\n",
    "# Repeates after 75 bytes\n",
    "\n",
    "\n",
    "b, b2, b4, b8, s = convert_hexstring(customer_data)\n",
    "\n",
    "b4['index'] = b4.index\n",
    "b4.set_index('4byte', inplace=True)\n",
    "\n",
    "print(b4.loc[\"57686974\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_packets(filename):\n",
    "    return pd.read_csv(f\"./SERIAL_CAPTURE/{filename}\", sep=',')\n",
    "\n",
    "def load_samples(filename, sep):\n",
    "    return pd.read_csv(f\"./ENIGMA_SAMPLES/{filename}\", sep=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeats after ~22 packets therfore 250 packets contians 20 rows of data\n",
    "\n",
    "packets = load_packets(\"bev_config.csv\")#.iloc[0:500]\n",
    "\n",
    "#Remove start bit and packet length data\n",
    "packets['packet']  = packets['packet'].str.slice(6, 1000000)\n",
    "#Seperate address out of packet\n",
    "packets['address'] = packets['packet'].str.slice(0, 22)\n",
    "#Remove address from packet\n",
    "packets['packet']  = packets['packet'].str.slice(22, 1000000)\n",
    "\n",
    "\n",
    "#Se merges to TX and RX packets into one row\n",
    "combined  = packets[packets[\"dir\"] == 'tx']\n",
    "rx_packets = packets[packets[\"dir\"] == 'rx']['packet']\n",
    "\n",
    "combined = combined.rename(columns={'packet':'tx'})\n",
    "combined = combined.drop(columns=['dir','len'])\n",
    "combined['rx'] = rx_packets.values\n",
    "packets = combined\n",
    "\n",
    "packets.to_csv(\"./ENIGMA_OUTPUT/packets_bev.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVED HEADER ADDED A COMMER FOR EXTRA ROW\n",
    "sample_data = load_samples(\"bev_conf_cust_table.csv\", \";\")\n",
    "sample_data = sample_data.set_index('Unnamed: 0')\n",
    "\n",
    "sample_data = sample_data.filter(regex='^((?!Unnamed).)*$')\n",
    "sample_data = sample_data.iloc[:, : 20]\n",
    "\n",
    "sample_data.to_csv(\"./ENIGMA_OUTPUT/sample_data_bev.csv\")\n",
    "\n",
    "\n",
    "#strings = b8.iloc[58::75, :]\n",
    "\n",
    "#mask = b.iloc[::75, :]\n",
    "\n",
    "masked_b = {}\n",
    "masked_2b = {}\n",
    "masked_4b = {}   \n",
    "masked_8b = {}\n",
    "for i in range(0, 158):\n",
    "    mask_b = b.iloc[i::75, :]\n",
    "    mask_b2 = b2.iloc[i::75, :]\n",
    "    mask_b4 = b4.iloc[i::75, :]\n",
    "    mask_b8 = b8.iloc[i::75, :]\n",
    "\n",
    "    masked_b[i]  = mask_b['unsigned'].values[:18]\n",
    "    masked_2b[i] = mask_b2['unsigned'].values[:18]\n",
    "    masked_4b[i] = mask_b4['unsigned'].values[:18]\n",
    "    masked_8b[i] = mask_b8['unsigned'].values[:18]\n",
    "    \"\"\"\n",
    "    for index, row in sample_data.iterrows():\n",
    "        print(mask['unsigned'].values)\n",
    "        if all(np.array(row.values) == np.array(mask['unsigned'].values)):\n",
    "            print(f\"Found match: {index}\")\n",
    "    \"\"\"\n",
    "mask_b = pd.DataFrame(masked_b).T\n",
    "mask_b2 = pd.DataFrame(masked_2b).T\n",
    "mask_b4 = pd.DataFrame(masked_4b).T\n",
    "mask_b8 = pd.DataFrame(masked_8b).T\n",
    "\n",
    "for index, row in sample_data.iterrows():\n",
    "    for i in range(0, 100):\n",
    "        if all(np.array(row.values[1:18]) == np.array(mask_b2.iloc[i].values[1:18])):\n",
    "            print(f\"{index} found match @ offset {i}\")\n",
    "  \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_df(df):\n",
    "    #This is so ugly\n",
    "    tok_data = {}\n",
    "    for column in df:\n",
    "        tokens = {}\n",
    "        token_data =[]\n",
    "        token_id = 0\n",
    "        for value in df[column]:\n",
    "            if value not in tokens:\n",
    "                token_data.append(token_id)\n",
    "                tokens[value] = token_id\n",
    "                token_id += 1\n",
    "            else:\n",
    "                token_data.append(tokens[value])\n",
    "        \n",
    "        tok_data[column] = token_data\n",
    "    return pd.DataFrame(tok_data)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Works well for patterned data\n",
    "token_df = tok_sample.add_prefix('sample_').T\n",
    "\n",
    "for address in addresses:\n",
    "    token_df = pd.concat([token_df, address_df[address]['T8'].add_prefix(f'{address}_T8_').T], axis=0)\n",
    "    token_df = pd.concat([token_df, address_df[address]['T16'].add_prefix(f'{address}_T16_').T], axis=0)\n",
    "    token_df = pd.concat([token_df, address_df[address]['T32'].add_prefix(f'{address}_T32_').T], axis=0)\n",
    "    token_df = pd.concat([token_df, address_df[address]['T64'].add_prefix(f'{address}_T64_').T], axis=0)\n",
    "\n",
    "a=[]\n",
    "\n",
    "        \n",
    "packets[packets['address'] == '0300010000000100014d00'].to_csv('./ENIGMA_OUTPUT/error_0300010000000100014d00')\n",
    "#itterate over token_df and compare with sample_data\n",
    "#token_df = token_df.T\n",
    "#token_df = token_df.reset_index(drop=True)\n",
    "#token_df = token_df.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "TX Packet Makup - +26bytes\n",
    "\n",
    "b0  -> (1 byte) f0 start bit\n",
    "b1\n",
    "b2  -> (2 bytes) Length of packet \n",
    "b3\n",
    "b19 -> (16 bytes) Address / Command \n",
    "b20\n",
    "b25 -> (5 Bytes .. imagine no upper limit) Fn Data\n",
    "\n",
    "\n",
    "RX Packet Makup\n",
    "\n",
    "b0  -> (1 byte) f0 start bit\n",
    "b1\n",
    "b2  -> (2 bytes) Length of packet \n",
    "b3\n",
    "b19 -> (16 bytes) Address / Command  - Always returns same as TX\n",
    "b20\n",
    "bXX -> (XX Bytes .. can be thousands) Response data .. Some of this is always the same as TX?\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Errors \n",
    "\n",
    "```Text\n",
    "TX order of packets\n",
    "Preamble? \n",
    "\n",
    "0300010000000100865200 - 0001000000000000000000de    *** RX contains num errors?\n",
    "Data\n",
    "\n",
    "Byte                                              25  \n",
    "Desc                                              Nr \n",
    "                                                  $$$$\n",
    "000100000000000000000014003a003c00ffffffffffff7701c80005007000000400003300000000004e\n",
    "\n",
    "0500010000000100004d02 - 0000000000000000000000055b\n",
    "0500010000000100004d03 - 00000000000000000000000b62\n",
    "\n",
    "Error number 1\n",
    "0500010000000100004d01 - 00000000000000000000000156   ***\n",
    "0500010000000100004d04 - 0000000000000000000000010059 ???\n",
    "0300010000000100004d00 - 000100000000000000000053     *** \n",
    "0300010000000100014d00 - 000100010000000b00000060     ??? RX contains all data\n",
    "0300010000000100014d05 - 000000000000000000000058     ***\n",
    "0300010000000100014d04 - 000000000000000000000057     ***\n",
    "0300010000000100014d03 - 000000000000000000000056     ***\n",
    "0300010000000100014d06 - 000000000000000000000059     ***\n",
    "0300010000000100014d07 - 00000000000000000000005a     ***\n",
    "0300010000000100014d08 - 00000000000000000000005b     ***\n",
    "0300010000000100014d09 - 00000000000000000000005c     ***\n",
    "\n",
    "\n",
    "Error number 2\n",
    "0500010000000100004d01 - 00000000000000000000000156\n",
    "0500010000000100004d04 - 000000000000000000000002005a\n",
    "0300010000000100004d00 - 000100000000000000000053\n",
    "0300010000000100014d00 - 000100020000000b00000061\n",
    "0300010000000100014d05 - 000000000000000000000058\n",
    "0300010000000100014d04 - 000000000000000000000057\n",
    "0300010000000100014d03 - 000000000000000000000056\n",
    "0300010000000100014d06 - 000000000000000000000059\n",
    "0300010000000100014d07 - 00000000000000000000005a\n",
    "0300010000000100014d08 - 00000000000000000000005b\n",
    "0300010000000100014d09 - 00000000000000000000005c\n",
    "\n",
    "Error number 3\n",
    "0500010000000100004d01 - 00000000000000000000000156\n",
    "0500010000000100004d04 - 000000000000000000000003005b\n",
    "0300010000000100004d00 - 000100000000000000000053\n",
    "0300010000000100014d00 - 000100030000000b00000062\n",
    "0300010000000100014d05 - 000000000000000000000058\n",
    "0300010000000100014d04 - 000000000000000000000057\n",
    "0300010000000100014d03 - 000000000000000000000056\n",
    "0300010000000100014d06 - 000000000000000000000059\n",
    "0300010000000100014d07 - 00000000000000000000005a\n",
    "0300010000000100014d08 - 00000000000000000000005b\n",
    "0300010000000100014d09 - 00000000000000000000005c\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "No postamble\n",
    "\n",
    "```\n",
    "\n",
    "```Text\n",
    "TX \n",
    "Address\n",
    "0300010000000100014d00\n",
    "Fn Data etc...\n",
    "000100010000000b00000060\n",
    "000100020000000b00000061\n",
    "000100030000000b00000062\n",
    "\n",
    "RX\n",
    "Address\n",
    "0300010000000100014d00\n",
    "Data - all 2 byte little endian\n",
    "\n",
    "Byte  3               11  13  15  17  19  21  23  25  27\n",
    "Desc  Nr              Fnr FlagSec Min Hr  Day Mon Anz Inf Text-Info Buffer\n",
    "      @@@@            !!!!$$$$@@@@!!!!$$$$@@@@!!!!$$$$@@@@.........\n",
    "000100020000000b0000003e0001001e0031000d001900020004001a00000000000000000000000000000000000000000000000000000000000000000035\n",
    "```\n",
    "\n",
    "Fehlertext is mapped from F-Nr\n",
    "\n",
    "Info-Txt ?? not useful data anyway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preamble = packets.iloc[0:3]\n",
    "'0300010000000100865200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_packets(packets, address, index_of_data, bytes, conversion):\n",
    "    #Mask out packets with wrong packet address\n",
    "    p = packets[packets['address'] == address]\n",
    "    data = []\n",
    "    for index, row in p.iterrows():  \n",
    "        data.append(conversion(row['rx'][index_of_data:index_of_data+bytes*2]))\n",
    "    \n",
    "    return data\n",
    "\n",
    "#Read f-nr\n",
    "data = read_packets(packets, \"0300010000000100014d08\", 22, 1, convert_b_unsigned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268437504\n",
      "1978-07-04 22:58:24\n",
      "1048584\n",
      "1970-01-13 04:16:24\n",
      "218107904\n",
      "1976-11-29 09:31:44\n",
      "851984\n",
      "1970-01-10 21:39:44\n",
      "419433728\n",
      "1983-04-17 14:22:08\n",
      "1638413\n",
      "1970-01-20 00:06:53\n",
      "33560832\n",
      "1971-01-24 11:27:12\n",
      "131097\n",
      "1970-01-02 13:24:57\n"
     ]
    }
   ],
   "source": [
    "# Think datetime is contained within \n",
    "\n",
    "dt = '00080010000d0019000200'\n",
    "\n",
    "# Window in 32 bit & 64 bit numbers\n",
    "b4 = [dt[(i*2):(i*2)+8] for i in range(0, int(len(dt)/2-3))]\n",
    "b8 =  [dt[(i*2):(i*2)+16] for i in range(0, int(len(dt)/2-7))]\n",
    "\n",
    "for b in b4: \n",
    "    dec = int.from_bytes(bytes.fromhex(b), byteorder=\"little\")\n",
    "    print(dec)\n",
    "    try:\n",
    "        date = datetime.datetime.fromtimestamp(dec)\n",
    "        print(date)\n",
    "    except:\n",
    "        print(f\"Failed to convert {b} to datetime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_data(sample_series, read_series):\n",
    "    if len(sample_series) != len(read_series):\n",
    "        print(\"Length of series does not match\")\n",
    "        return \n",
    "\n",
    "    return pd.DataFrame({'sample': sample_series, 'read': read_series, \"compare\": sample_series == read_series})\n",
    "\n",
    "print(sample_data['Anzahl'].values)\n",
    "\n",
    "ret = compare_data(sample_data['Anzahl'].values, data)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
