{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tx = \"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\"\n",
    "tx = \"f0f2050300010000000100814500\"\n",
    "def convert_hexstring_bytearray(hexstring):\n",
    "    chunks = [tx[i:i+2] for i in range(0, len(tx), 2)]\n",
    "    #print(chunks)\n",
    "    dec = []\n",
    "    for byte in chunks:\n",
    "        dec.append(int(byte, 16))\n",
    "\n",
    "    return dec\n",
    "\n",
    "ar = convert_hexstring_bytearray(tx)\n",
    "print(ar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "# byte to value conversions\n",
    "\n",
    "def convert_b_signed(byte):\n",
    "    return struct.unpack('b', bytes.fromhex(byte))[0]\n",
    "\n",
    "def convert_b_unsigned(byte):\n",
    "    return struct.unpack('B', bytes.fromhex(byte))[0]\n",
    "\n",
    "def convert_b_char(byte):\n",
    "    return struct.unpack('c', bytes.fromhex(byte))[0]\n",
    "\n",
    "# LITTLE ENDIAN\n",
    "def convert_unsigned(hex):\n",
    "    dec = int.from_bytes(bytes.fromhex(hex), byteorder=\"little\")\n",
    "    return dec\n",
    "\n",
    "def convert_signed(hex):\n",
    "    bits = len(hex) * 4\n",
    "    dec  = convert_unsigned(hex)\n",
    "    if dec > (bits-1)**2:\n",
    "        dec = dec - bits**2\n",
    "    return dec\n",
    "\n",
    "def convert_2b_float(byte_2):\n",
    "    return struct.unpack('e', bytes.fromhex(byte_2))[0]\n",
    "\n",
    "def convert_4b_float(byte_4):\n",
    "    return struct.unpack('f', bytes.fromhex(byte_4))[0]\n",
    "\n",
    "def convert_8b_double(byte_8):\n",
    "    return struct.unpack('d', bytes.fromhex(byte_8))[0]\n",
    "\n",
    "def convert_string(byte):\n",
    "    return struct.unpack('s', bytes.fromhex(byte))[0]\n",
    "\n",
    "\n",
    "\n",
    "def convert_byte(byte):\n",
    "    char = convert_b_char(byte)\n",
    "    ub = convert_unsigned(byte)\n",
    "    sb = convert_signed(byte)\n",
    "\n",
    "    return [sb , ub, char]\n",
    "\n",
    "def convert_2b(byte_2):\n",
    "    u2 = convert_unsigned(byte_2)\n",
    "    s2 = convert_signed(byte_2)\n",
    "    float_s = convert_2b_float(byte_2)\n",
    "    return [s2, u2, float_s ]\n",
    "\n",
    "def convert_4b(byte_4):\n",
    "    u4 = convert_unsigned(byte_4)\n",
    "    s4 = convert_signed(byte_4)\n",
    "    f = convert_4b_float(byte_4)\n",
    "\n",
    "    return [ s4, u4, f]\n",
    "\n",
    "def convert_8b(byte_8):\n",
    "    u8 = convert_unsigned(byte_8)\n",
    "    s8 = convert_signed(byte_8)\n",
    "    double = convert_8b_double(byte_8)\n",
    "\n",
    "    return [s8, u8, double]\n",
    "\n",
    "# Windows hexstring into byte, b2, b4, b8 and converts data into typical data types\n",
    "# Returns dataframes with the converted data (index indicated position of data in hexstring)\n",
    "def convert_hexstring(data : str):\n",
    "    # Window string into chunks of different byte sizes\n",
    "    # Make window jump by 2 chars as 2chars = 1 byte\n",
    "    b =  [data[(i*2):(i*2)+2] for i in range(0, int(len(data)/2))]\n",
    "    b2 = [data[(i*2):(i*2)+4] for i in range(0, int(len(data)/2-1))]\n",
    "    b4 = [data[(i*2):(i*2)+8] for i in range(0, int(len(data)/2-3))]\n",
    "    b8 =  [data[(i*2):(i*2)+16] for i in range(0, int(len(data)/2-7))]\n",
    "\n",
    "\n",
    "    b_conversion  = pd.DataFrame(columns=['byte',  'signed', 'unsigned', 'char'])\n",
    "    b2_conversion = pd.DataFrame(columns=['2byte', 'signed', 'unsigned', 'float'])\n",
    "    b4_conversion = pd.DataFrame(columns=['4byte', 'signed', 'unsigned', 'float'])\n",
    "    b8_conversion = pd.DataFrame(columns=['8byte', 'signed', 'unsigned', 'double'])\n",
    " \n",
    "    \"\"\"\n",
    "    conv = []\n",
    "    for x in b_conversion['char'].values:\n",
    "        try:\n",
    "            a = str(x, 'utf-8')\n",
    "            conv.append(a)\n",
    "        except:\n",
    "            conv.append(\"@\")\n",
    "    \"\"\"\n",
    "    string = \"\"\n",
    "    \n",
    "    b_conversion = b_conversion.drop('char', axis=1)\n",
    "\n",
    "    for i, byte in enumerate(b):\n",
    "        b_conversion.loc[i] = [byte] + convert_byte(byte)[0:2]\n",
    "\n",
    "    for i, byte_2 in enumerate(b2):\n",
    "        b2_conversion.loc[i] = [byte_2] + convert_2b(byte_2)\n",
    "    \n",
    "    for i, byte_4 in enumerate(b4):\n",
    "        b4_conversion.loc[i] = [byte_4] + convert_4b(byte_4)\n",
    "    \n",
    "    for i, byte_8 in enumerate(b8):\n",
    "        b8_conversion.loc[i] = [byte_8] + convert_8b(byte_8)\n",
    "\n",
    "    return b_conversion, b2_conversion, b4_conversion, b8_conversion, string\n",
    "\n",
    "\n",
    "cap = \"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\"\n",
    "ame = \"f016000500010000000100054902000000000000000000000057\"\n",
    "\n",
    "b, b2, b4, b8, s = convert_hexstring(ame)\n",
    "print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_packets(filename):\n",
    "    return pd.read_csv(f\"./SERIAL_CAPTURE/{filename}\", sep=',')\n",
    "\n",
    "def load_samples(filename, sep):\n",
    "    return pd.read_csv(f\"./ENIGMA_SAMPLES/{filename}\", sep=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeats after ~22 packets therfore 250 packets contians 20 rows of data\n",
    "\n",
    "packets = load_packets(\"errors_200.csv\")#.iloc[0:500]\n",
    "\n",
    "#Remove start bit and packet length data\n",
    "packets['packet']  = packets['packet'].str.slice(6, 1000000)\n",
    "#Seperate address out of packet\n",
    "packets['address'] = packets['packet'].str.slice(0, 22)\n",
    "#Remove address from packet\n",
    "packets['packet']  = packets['packet'].str.slice(22, 1000000)\n",
    "\n",
    "\n",
    "#Se merges to TX and RX packets into one row\n",
    "combined  = packets[packets[\"dir\"] == 'tx']\n",
    "rx_packets = packets[packets[\"dir\"] == 'rx']['packet']\n",
    "\n",
    "combined = combined.rename(columns={'packet':'tx'})\n",
    "combined = combined.drop(columns=['dir','len'])\n",
    "combined['rx'] = rx_packets.values\n",
    "packets = combined\n",
    "\n",
    "starts_with = packets.apply(lambda row: row['rx'].startswith(row['rx'][0:]), axis=1)\n",
    "\n",
    "solved_packets = packets\n",
    "\n",
    "\n",
    "#packets.to_csv(\"mach_conf.csv\", index=True)\n",
    "nr          = [False for i in range(packets.shape[0])] \n",
    "f_nr        = [False for i in range(packets.shape[0])] \n",
    "info_txt_n  = [False for i in range(packets.shape[0])] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVED HEADER ADDED A COMMER FOR EXTRA ROW\n",
    "sample_data = load_samples(\"errors_200.csv\", \",\")\n",
    "#sample_data = sample_data[0:20]\n",
    "\n",
    "\"\"\"\n",
    "sample_data['comb_datum'] = sample_data['Datum'].astype(str) + \".2023::\" + sample_data['Zeit'].astype(str)\n",
    "\n",
    "sample_data['unixtime'] = pd.to_datetime(sample_data['comb_datum'], format='%d.%m.%Y::%H:%M:%S')\n",
    "sample_data['unixtime_s'] =  sample_data['unixtime'].astype('uint64')   / 1000000000\n",
    "sample_data['unixtime_ms'] = sample_data['unixtime'].astype('uint64')   / 1000000\n",
    "sample_data['unixtime_ns'] = sample_data['unixtime'].astype('uint64')   / 1000\n",
    "sample_data['unixtime_D'] =  sample_data['unixtime_s'].astype('uint64') / 86400\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adresses which repeat in the data\n",
    "addresses = ['0500010000000100004d01', '0500010000000100004d04', '0300010000000100004d00', '0300010000000100014d00', '0300010000000100014d05', '0300010000000100014d04', '0300010000000100014d03', '0300010000000100014d06', '0300010000000100014d07', '0300010000000100014d08', '0300010000000100014d09']\n",
    "\n",
    "\n",
    "# Brainwave, compare packets with the same address\n",
    "address_packets = packets.groupby('address')['rx'].apply(list).reset_index(name='packets')\n",
    "\n",
    "address_packets['len'] = address_packets['packets'].apply(lambda x: len(x))\n",
    "address_packets = address_packets[address_packets['len'] > 1]\n",
    "\n",
    "def extraction(packet_list):\n",
    "    usigned_byte = pd.DataFrame()\n",
    "    for i, packet in enumerate(packet_list[0]):\n",
    "        b, b2, b4, b8, s = convert_hexstring(packet)\n",
    "\n",
    "        usigned_byte[f'Packet {i} S8']  = b['signed']\n",
    "        usigned_byte[f'Packet {i} U8']  = b['unsigned']\n",
    "        usigned_byte[f'Packet {i} S16'] = b2['signed']\n",
    "        usigned_byte[f'Packet {i} U16'] = b2['unsigned']\n",
    "        usigned_byte[f'Packet {i} S32'] = b4['signed']\n",
    "        usigned_byte[f'Packet {i} U32'] = b4['unsigned']\n",
    "        usigned_byte[f'Packet {i} S64'] = b8['signed']\n",
    "        usigned_byte[f'Packet {i} U64'] = b8['unsigned']\n",
    "    \n",
    "    return usigned_byte\n",
    "\n",
    "def tokenise_df(df):\n",
    "    #This is so ugly\n",
    "    tok_data = {}\n",
    "    for column in df:\n",
    "        tokens = {}\n",
    "        token_data =[]\n",
    "        token_id = 0\n",
    "        for value in df[column]:\n",
    "            if value not in tokens:\n",
    "                token_data.append(token_id)\n",
    "                tokens[value] = token_id\n",
    "                token_id += 1\n",
    "            else:\n",
    "                token_data.append(tokens[value])\n",
    "        \n",
    "        tok_data[column] = token_data\n",
    "    return pd.DataFrame(tok_data)\n",
    "\n",
    "tok_sample = tokenise_df(sample_data)\n",
    "\n",
    "address_df = {}\n",
    "for address in addresses:\n",
    "    mask = address_packets[address_packets['address'] == address]\n",
    "    ex = extraction(mask['packets'].values)\n",
    "    address_df[address] = {\n",
    "        \"S8\" : ex.filter(regex='S8'),\n",
    "        \"U8\" : ex.filter(regex='U8'),\n",
    "        \"T8\"  : tokenise_df(ex.filter(regex='U8').T),\n",
    "        \"S16\" : ex.filter(regex='S16'),\n",
    "        \"U16\" : ex.filter(regex='U16'),\n",
    "        \"T16\" : tokenise_df(ex.filter(regex='U16').T),\n",
    "        \"S32\" : ex.filter(regex='S32'),\n",
    "        \"U32\" : ex.filter(regex='U32'),\n",
    "        \"T32\" : tokenise_df(ex.filter(regex='U32').T),\n",
    "        \"S64\" : ex.filter(regex='S64'),\n",
    "        \"U64\" : ex.filter(regex='U64'),\n",
    "        \"T64\" : tokenise_df(ex.filter(regex='U64').T)\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Works well for patterned data\n",
    "token_df = tok_sample.add_prefix('sample_').T\n",
    "\n",
    "for address in addresses:\n",
    "    token_df = pd.concat([token_df, address_df[address]['T8'].add_prefix(f'{address}_T8_').T], axis=0)\n",
    "    token_df = pd.concat([token_df, address_df[address]['T16'].add_prefix(f'{address}_T16_').T], axis=0)\n",
    "    token_df = pd.concat([token_df, address_df[address]['T32'].add_prefix(f'{address}_T32_').T], axis=0)\n",
    "    token_df = pd.concat([token_df, address_df[address]['T64'].add_prefix(f'{address}_T64_').T], axis=0)\n",
    "\n",
    "a=[]\n",
    "for index, row in token_df.iterrows():\n",
    "    if all(np.array(row.values) == np.array(token_df.loc['sample_Info-Txt'].values)):\n",
    "        a.append(f\"Found Info-Txt at index {index}\")\n",
    "\n",
    "        \n",
    "packets[packets['address'] == '0300010000000100014d00'].to_csv('./ENIGMA_OUTPUT/error_0300010000000100014d00')\n",
    "#itterate over token_df and compare with sample_data\n",
    "#token_df = token_df.T\n",
    "#token_df = token_df.reset_index(drop=True)\n",
    "#token_df = token_df.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "TX Packet Makup - +26bytes\n",
    "\n",
    "b0  -> (1 byte) f0 start bit\n",
    "b1\n",
    "b2  -> (2 bytes) Length of packet \n",
    "b3\n",
    "b19 -> (16 bytes) Address / Command \n",
    "b20\n",
    "b25 -> (5 Bytes .. imagine no upper limit) Fn Data\n",
    "\n",
    "\n",
    "RX Packet Makup\n",
    "\n",
    "b0  -> (1 byte) f0 start bit\n",
    "b1\n",
    "b2  -> (2 bytes) Length of packet \n",
    "b3\n",
    "b19 -> (16 bytes) Address / Command  - Always returns same as TX\n",
    "b20\n",
    "bXX -> (XX Bytes .. can be thousands) Response data .. Some of this is always the same as TX?\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Errors \n",
    "\n",
    "```Text\n",
    "TX order of packets\n",
    "Preamble? \n",
    "\n",
    "0300010000000100865200 - 0001000000000000000000de     *** RX contains num errors?\n",
    "Data\n",
    "Byte                                              25  \n",
    "Desc                                              No \n",
    "                                                  $$$$\n",
    "000100000000000000000014003a003c00ffffffffffff7701c80005007000000400003300000000004e\n",
    "\n",
    "0500010000000100004d02 - 0000000000000000000000055b\n",
    "0500010000000100004d03 - 00000000000000000000000b62\n",
    "\n",
    "Error number 1\n",
    "0500010000000100004d01 - 00000000000000000000000156   ***\n",
    "0500010000000100004d04 - 0000000000000000000000010059 ???\n",
    "0300010000000100004d00 - 000100000000000000000053     *** \n",
    "0300010000000100014d00 - 000100010000000b00000060     ??? RX contains all data\n",
    "0300010000000100014d05 - 000000000000000000000058     ***\n",
    "0300010000000100014d04 - 000000000000000000000057     ***\n",
    "0300010000000100014d03 - 000000000000000000000056     ***\n",
    "0300010000000100014d06 - 000000000000000000000059     ***\n",
    "0300010000000100014d07 - 00000000000000000000005a     ***\n",
    "0300010000000100014d08 - 00000000000000000000005b     ***\n",
    "0300010000000100014d09 - 00000000000000000000005c     ***\n",
    "\n",
    "\n",
    "Error number 2\n",
    "0500010000000100004d01 - 00000000000000000000000156\n",
    "0500010000000100004d04 - 000000000000000000000002005a\n",
    "0300010000000100004d00 - 000100000000000000000053\n",
    "0300010000000100014d00 - 000100020000000b00000061\n",
    "0300010000000100014d05 - 000000000000000000000058\n",
    "0300010000000100014d04 - 000000000000000000000057\n",
    "0300010000000100014d03 - 000000000000000000000056\n",
    "0300010000000100014d06 - 000000000000000000000059\n",
    "0300010000000100014d07 - 00000000000000000000005a\n",
    "0300010000000100014d08 - 00000000000000000000005b\n",
    "0300010000000100014d09 - 00000000000000000000005c\n",
    "\n",
    "Error number 3\n",
    "0500010000000100004d01 - 00000000000000000000000156\n",
    "0500010000000100004d04 - 000000000000000000000003005b\n",
    "0300010000000100004d00 - 000100000000000000000053\n",
    "0300010000000100014d00 - 000100030000000b00000062\n",
    "0300010000000100014d05 - 000000000000000000000058\n",
    "0300010000000100014d04 - 000000000000000000000057\n",
    "0300010000000100014d03 - 000000000000000000000056\n",
    "0300010000000100014d06 - 000000000000000000000059\n",
    "0300010000000100014d07 - 00000000000000000000005a\n",
    "0300010000000100014d08 - 00000000000000000000005b\n",
    "0300010000000100014d09 - 00000000000000000000005c\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "No postamble\n",
    "\n",
    "```\n",
    "\n",
    "```Text\n",
    "TX \n",
    "Address\n",
    "0300010000000100014d00\n",
    "Fn Data etc...\n",
    "000100010000000b00000060\n",
    "000100020000000b00000061\n",
    "000100030000000b00000062\n",
    "\n",
    "RX\n",
    "Address\n",
    "0300010000000100014d00\n",
    "Data - all 2 byte little endian\n",
    "\n",
    "Byte  3               11  13  15  17  19  21  23  25  27\n",
    "Desc  Nr              Fnr FlagSec Min Hr  Day Mon Anz Inf Text-Info Buffer\n",
    "      @@@@            !!!!$$$$@@@@!!!!$$$$@@@@!!!!$$$$@@@@.........\n",
    "000100020000000b0000003e0001001e0031000d001900020004001a00000000000000000000000000000000000000000000000000000000000000000035\n",
    "```\n",
    "\n",
    "Fehlertext is mapped from F-Nr\n",
    "\n",
    "Info-Txt ?? not useful data anyway\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preamble = packets.iloc[0:3]\n",
    "'0300010000000100865200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_packets(packets, address, index_of_data, bytes, conversion):\n",
    "    #Mask out packets with wrong packet address\n",
    "    p = packets[packets['address'] == address]\n",
    "    data = []\n",
    "    for index, row in p.iterrows():  \n",
    "        data.append(conversion(row['rx'][index_of_data:index_of_data+bytes*2]))\n",
    "    \n",
    "    return data\n",
    "\n",
    "#Read f-nr\n",
    "data = read_packets(packets, \"0300010000000100014d08\", 22, 1, convert_b_unsigned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268437504\n",
      "1978-07-04 22:58:24\n",
      "1048584\n",
      "1970-01-13 04:16:24\n",
      "218107904\n",
      "1976-11-29 09:31:44\n",
      "851984\n",
      "1970-01-10 21:39:44\n",
      "419433728\n",
      "1983-04-17 14:22:08\n",
      "1638413\n",
      "1970-01-20 00:06:53\n",
      "33560832\n",
      "1971-01-24 11:27:12\n",
      "131097\n",
      "1970-01-02 13:24:57\n"
     ]
    }
   ],
   "source": [
    "# Think datetime is contained within \n",
    "\n",
    "dt = '00080010000d0019000200'\n",
    "\n",
    "# Window in 32 bit & 64 bit numbers\n",
    "b4 = [dt[(i*2):(i*2)+8] for i in range(0, int(len(dt)/2-3))]\n",
    "b8 =  [dt[(i*2):(i*2)+16] for i in range(0, int(len(dt)/2-7))]\n",
    "\n",
    "for b in b4: \n",
    "    dec = int.from_bytes(bytes.fromhex(b), byteorder=\"little\")\n",
    "    print(dec)\n",
    "    try:\n",
    "        date = datetime.datetime.fromtimestamp(dec)\n",
    "        print(date)\n",
    "    except:\n",
    "        print(f\"Failed to convert {b} to datetime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_data(sample_series, read_series):\n",
    "    if len(sample_series) != len(read_series):\n",
    "        print(\"Length of series does not match\")\n",
    "        return \n",
    "\n",
    "    return pd.DataFrame({'sample': sample_series, 'read': read_series, \"compare\": sample_series == read_series})\n",
    "\n",
    "print(sample_data['Anzahl'].values)\n",
    "\n",
    "ret = compare_data(sample_data['Anzahl'].values, data)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
